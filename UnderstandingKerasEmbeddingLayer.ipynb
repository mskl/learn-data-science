{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:30.906564Z",
     "start_time": "2019-03-26T23:21:28.046986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:31.843467Z",
     "start_time": "2019-03-26T23:21:31.839197Z"
    }
   },
   "outputs": [],
   "source": [
    "from string import printable\n",
    "\n",
    "text = \"ahoj vole\"\n",
    "text_tokens = [printable.index(x) + 1 for x in text if x in printable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:32.385784Z",
     "start_time": "2019-03-26T23:21:32.381857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahoj vole\n",
      "[11, 18, 25, 20, 95, 32, 25, 22, 15]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:32.859551Z",
     "start_time": "2019-03-26T23:21:32.854373Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "texts = [\"aaaahoj vole\",\n",
    "        \"uz je zase rano\",\n",
    "        \"vstavej do prace\"]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, lower=False, char_level=True, oov_token=True)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "texts_tokenized = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:33.743112Z",
     "start_time": "2019-03-26T23:21:33.734166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  2  2  2  2 11  5  6  3  7  5 12  4]\n",
      " [ 0  0  0  0  0 13  8  3  6  4  3  8  2  9  4  3 10  2 14  5]\n",
      " [ 0  0  0  0  7  9 15  2  7  4  6  3 16  5  3 17 10  2 18  4]]\n",
      "number of chars: 19\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# maximum length of arrays of characters\n",
    "padded_len = 20\n",
    "\n",
    "# number of characters\n",
    "num_chars = len(tokenizer.word_index) + 1\n",
    "\n",
    "texts_tokenized_padded = pad_sequences(texts_tokenized, maxlen=padded_len)\n",
    "print(texts_tokenized_padded)\n",
    "print(\"number of chars:\", num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:34.812334Z",
     "start_time": "2019-03-26T23:21:34.286187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "categories = [\"hovno\",\n",
    "              \"ne\",\n",
    "              \"ne\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "target = np.array(categories, dtype=\"str\")\n",
    "target = label_encoder.fit_transform(target)\n",
    "target = to_categorical(target, num_classes=2)\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:35.130777Z",
     "start_time": "2019-03-26T23:21:35.011605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 2)             38        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# Input\n",
    "main_input = Input(shape=(padded_len,), dtype='int32')\n",
    "emb = Embedding(input_dim=num_chars, output_dim=2, input_length=padded_len)(main_input) \n",
    "\n",
    "f = Flatten()(emb)\n",
    "output = Dense(2, activation='softmax')(f)\n",
    "\n",
    "# Compile model and define optimizer\n",
    "model = Model(inputs=[main_input], output=[output])\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.summary()\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:36.129130Z",
     "start_time": "2019-03-26T23:21:36.117631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  2,  2,  2,  2, 11,  5,  6,  3,\n",
       "         7,  5, 12,  4],\n",
       "       [ 0,  0,  0,  0,  0, 13,  8,  3,  6,  4,  3,  8,  2,  9,  4,  3,\n",
       "        10,  2, 14,  5],\n",
       "       [ 0,  0,  0,  0,  7,  9, 15,  2,  7,  4,  6,  3, 16,  5,  3, 17,\n",
       "        10,  2, 18,  4]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:36.690065Z",
     "start_time": "2019-03-26T23:21:36.685723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:21:39.023209Z",
     "start_time": "2019-03-26T23:21:37.884267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6994 - acc: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.6667\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6982 - acc: 0.6667\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6976 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6971 - acc: 0.6667\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6965 - acc: 0.6667\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6961 - acc: 0.6667\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6956 - acc: 0.6667\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6950 - acc: 0.6667\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6945 - acc: 0.6667\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6939 - acc: 0.6667\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.6667\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.6667\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.6667\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.6667\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.6667\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6907 - acc: 0.6667\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.6667\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.6667\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6892 - acc: 0.6667\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6886 - acc: 0.6667\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6883 - acc: 0.6667\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.6667\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.6667\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6866 - acc: 0.6667\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6860 - acc: 0.6667\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6857 - acc: 0.6667\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6850 - acc: 0.6667\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6845 - acc: 0.6667\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6841 - acc: 0.6667\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6834 - acc: 0.6667\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6829 - acc: 0.6667\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6824 - acc: 0.6667\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.6667\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6814 - acc: 0.6667\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6810 - acc: 0.6667\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6804 - acc: 0.6667\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6798 - acc: 0.6667\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6794 - acc: 0.6667\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6789 - acc: 0.6667\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6784 - acc: 0.6667\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6778 - acc: 0.6667\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6773 - acc: 0.6667\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6767 - acc: 0.6667\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6762 - acc: 0.6667\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6757 - acc: 0.6667\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6752 - acc: 0.6667\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6748 - acc: 0.6667\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6743 - acc: 0.6667\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6737 - acc: 0.6667\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6732 - acc: 0.6667\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.6667\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6722 - acc: 0.6667\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6716 - acc: 0.6667\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6712 - acc: 0.6667\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.6667\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6702 - acc: 0.6667\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6667\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6690 - acc: 0.6667\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6685 - acc: 0.6667\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6681 - acc: 0.6667\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6675 - acc: 0.6667\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6669 - acc: 0.6667\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6665 - acc: 0.6667\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6659 - acc: 0.6667\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6655 - acc: 0.6667\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6650 - acc: 0.6667\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 0.6667\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6639 - acc: 0.6667\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6633 - acc: 0.6667\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6629 - acc: 0.6667\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6623 - acc: 0.6667\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6618 - acc: 0.6667\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6612 - acc: 0.6667\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.6667\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6603 - acc: 0.6667\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6598 - acc: 0.6667\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6592 - acc: 0.6667\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6583 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6578 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6571 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6561 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6550 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6545 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6540 - acc: 1.0000\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6530 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6519 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6513 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6509 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6481 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6476 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ee4dc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(texts_tokenized_padded, target, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:22:00.708278Z",
     "start_time": "2019-03-26T23:22:00.701948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03068077,  0.04111718],\n",
       "        [-0.0192078 , -0.02749819],\n",
       "        [ 0.03773568, -0.00578519],\n",
       "        [ 0.00581718,  0.04050089],\n",
       "        [-0.0275339 ,  0.010617  ],\n",
       "        [ 0.05569772,  0.00710094],\n",
       "        [ 0.02340886,  0.0021414 ],\n",
       "        [-0.0127705 , -0.01261688],\n",
       "        [ 0.02951985, -0.03448699],\n",
       "        [ 0.02420008,  0.02796276],\n",
       "        [ 0.062594  ,  0.03381588],\n",
       "        [-0.0277958 , -0.02157798],\n",
       "        [-0.00395103,  0.03870299],\n",
       "        [-0.00723388, -0.02038889],\n",
       "        [-0.03784964, -0.05714012],\n",
       "        [-0.00364514,  0.02129517],\n",
       "        [ 0.04001863, -0.0082342 ],\n",
       "        [ 0.0050469 ,  0.03642355],\n",
       "        [ 0.02364043, -0.05844093]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for each character in vocabulary\n",
    "model.layers[1].get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
